# ğŸ½ï¸ Restaurant Ratings Prediction

## ğŸ“Œ Project Overview
This project predicts **restaurant ratings** using machine learning based on features such as location, cuisines, cost, delivery options, and user votes.  

The dataset contains **9,551 restaurants** with details like cuisines, city, average cost, votes, and aggregate rating.  
The goal is to build and evaluate ML models to predict **Aggregate Rating** and understand which features most influence ratings.

---

## ğŸ“‚ Repository Structure
restaurant-ratings/
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/ # raw dataset (not uploaded to GitHub if large)
â”‚ â””â”€â”€ processed/ # cleaned dataset
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ 01_eda.ipynb # exploratory analysis
â”‚ â”œâ”€â”€ 02_preprocessing.ipynb # feature engineering
â”‚ â”œâ”€â”€ 03_modeling.ipynb # model comparison
â”‚ â””â”€â”€ 04_evaluation.ipynb # evaluation & feature importance
â”œâ”€â”€ models/
â”‚ â””â”€â”€ best_model.pkl # saved Random Forest model
â”œâ”€â”€ outputs/
â”‚ â”œâ”€â”€ predictions.csv # predictions file
â”‚ â””â”€â”€ figures/ # plots (EDA + evaluation)
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ data_utils.py # load/save data helpers
â”‚ â”œâ”€â”€ features.py # feature engineering functions
â”‚ â”œâ”€â”€ train.py # training pipeline
â”‚ â””â”€â”€ predict.py # inference pipeline
â”œâ”€â”€ restaurant_ratings_final.ipynb # polished single notebook
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

yaml

---

## ğŸ› ï¸ Tech Stack
- **Python** (3.9+)  
- **Pandas, NumPy** â†’ data handling  
- **Matplotlib, Seaborn** â†’ visualization  
- **Scikit-learn** â†’ ML models, preprocessing  
- **Joblib** â†’ model persistence  
- **Jupyter Notebook** â†’ experimentation  

---

## ğŸ” Exploratory Data Analysis (EDA)
Key insights from the data:
- Most restaurants have ratings between **3.0 and 4.5**.  
- **Votes** (number of reviews) are highly skewed â†’ few restaurants have very high votes.  
- **Top cuisines**: North Indian, Chinese, Pizza, South Indian.  
- Ratings distribution varies by city.  

---

## ğŸ”§ Preprocessing
Steps taken:
- Filled missing values in `Cuisines`.  
- Extracted `PrimaryCuisine` from the first listed cuisine.  
- Converted Yes/No columns (`Has Table booking`, `Has Online delivery`) to 1/0.  
- Dropped irrelevant columns (`Restaurant ID`, `Address`, `Rating text`, etc.).  
- Standardized numeric features & one-hot encoded categorical features.  

---

## ğŸ¤– Modeling
Models compared:
- **Linear Regression** â†’ RMSE: ~1.23, RÂ²: ~0.33  
- **Decision Tree** â†’ RMSE: ~0.40, RÂ²: ~0.93  
- **Random Forest** â†’ RMSE: ~0.29, RÂ²: ~0.96 âœ… (best)  

---

## ğŸ“Š Evaluation & Feature Importance
Final model: **Random Forest Regressor**

- **MSE:** 0.086  
- **RMSE:** 0.294  
- **RÂ²:** 0.962  

## Top features:
1. **Votes** (most influential, ~94%)  
2. **Location (Longitude, Latitude)**  
3. **Average Cost for Two**  
4. **Cuisine Types** (North Indian, Chinese, American, etc.)  
5. **Service Features** (Online Delivery, Table Booking)  

---

## ğŸš€ How to Run Locally
1. Clone the repo:
   ```bash
   git clone https://github.com/<your-username>/restaurant-ratings.git
   cd restaurant-ratings
Create virtual environment:

bash
Copy code
python -m venv .venv
.venv\Scripts\activate   # Windows
# or
source .venv/bin/activate # Mac/Linux
Install requirements:

bash
Copy code
pip install -r requirements.txt
Train the model:

bash
Copy code
python -m src.train
Predict ratings on a dataset:

bash
Copy code
python -m src.predict data/raw/restaurant_ratings.csv
Open Jupyter notebooks for exploration:

bash
Copy code
jupyter notebook
ğŸ“ˆ Results
Random Forest achieved 96% accuracy (RÂ²) with low error (RMSE ~0.29).

The number of votes was the strongest predictor of ratings.

Cuisine type and delivery features added minor contributions.

## ğŸ“Š Example Plots  

### Distribution of Ratings  
![Rating Distribution](outputs/figures/rating_distribution.png)

### Top 15 Cuisines  
![Top Cuisines](outputs/figures/top_cuisines.png)

### Actual vs Predicted Ratings  
![Actual vs Predicted](outputs/figures/actual_vs_predicted.png)

### Feature Importance  
![Feature Importance](outputs/figures/feature_importance.png)

---

## ğŸ”® Future Work  
- Test advanced models: XGBoost, LightGBM, CatBoost.  
- Hyperparameter tuning for Random Forest.  
- Deploy an interactive **Streamlit web app** for predictions.  
- Use larger datasets or live API data.


ğŸ“œ License
This project is licensed under the MIT License.

yaml
Copy code

---

ğŸ‘‰ This README is **portfolio-ready**.  
Next step: you should add **a few plots (PNG)** into `outputs/figures/` and reference them in the README with:  

```markdown
![Feature Importance](outputs/figures/feature_importance.png) 
